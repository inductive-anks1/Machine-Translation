{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Imports"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-08-15 00:56:02.429608: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-08-15 00:56:02.920537: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-08-15 00:56:03.076083: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-08-15 00:56:03.681362: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-08-15 00:56:13.917092: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]},{"data":{"text/html":["        <script type=\"text/javascript\">\n","        window.PlotlyConfig = {MathJaxConfig: 'local'};\n","        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n","        if (typeof require !== 'undefined') {\n","        require.undef(\"plotly\");\n","        requirejs.config({\n","            paths: {\n","                'plotly': ['https://cdn.plot.ly/plotly-2.34.0.min']\n","            }\n","        });\n","        require(['plotly'], function(Plotly) {\n","            window._Plotly = Plotly;\n","        });\n","        }\n","        </script>\n","        "]},"metadata":{},"output_type":"display_data"}],"source":["import numpy as np \n","import pandas as pd \n","import random\n","import os\n","import tensorflow as tf\n","from tqdm import tqdm\n","import re\n","\n","from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import (Embedding, LSTM, Concatenate, Dropout,\n","                                     Input, Dense, Bidirectional, Layer, TimeDistributed)\n","\n","import tensorflow as tf\n","from tensorflow.keras.layers import Input, Dense, Embedding, Dropout, LayerNormalization, MultiHeadAttention, Add, Layer\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","\n","\n","import matplotlib.pyplot as plt \n","import seaborn as sns \n","import plotly.express as px\n","from plotly.offline import init_notebook_mode\n"]},{"cell_type":"markdown","metadata":{},"source":["## Loading Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-14T10:44:23.611215Z","iopub.status.busy":"2024-08-14T10:44:23.610610Z","iopub.status.idle":"2024-08-14T10:44:23.826563Z","shell.execute_reply":"2024-08-14T10:44:23.825571Z","shell.execute_reply.started":"2024-08-14T10:44:23.611185Z"},"trusted":true},"outputs":[],"source":["train = pd.read_parquet('/kaggle/input/machine-translation-data/train-00000-of-00001.parquet')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-14T10:44:25.871666Z","iopub.status.busy":"2024-08-14T10:44:25.870974Z","iopub.status.idle":"2024-08-14T10:44:25.884674Z","shell.execute_reply":"2024-08-14T10:44:25.883635Z","shell.execute_reply.started":"2024-08-14T10:44:25.871634Z"},"trusted":true},"outputs":[],"source":["test = pd.read_parquet('/kaggle/input/machine-translation-data/test-00000-of-00001.parquet')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-14T10:44:26.786399Z","iopub.status.busy":"2024-08-14T10:44:26.786038Z","iopub.status.idle":"2024-08-14T10:44:26.808451Z","shell.execute_reply":"2024-08-14T10:44:26.807675Z","shell.execute_reply.started":"2024-08-14T10:44:26.786369Z"},"trusted":true},"outputs":[],"source":["validate = pd.read_parquet('/kaggle/input/machine-translation-data/validation-00000-of-00001.parquet')"]},{"cell_type":"markdown","metadata":{},"source":["## Text Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-14T10:44:50.031450Z","iopub.status.busy":"2024-08-14T10:44:50.031068Z","iopub.status.idle":"2024-08-14T10:44:52.679437Z","shell.execute_reply":"2024-08-14T10:44:52.678586Z","shell.execute_reply.started":"2024-08-14T10:44:50.031419Z"},"trusted":true},"outputs":[],"source":["train[['dyu', 'fr']] = train['translation'].apply(pd.Series)\n","train.drop(columns=['translation'], inplace=True)\n","\n","validate[['dyu', 'fr']] = validate['translation'].apply(pd.Series)\n","validate.drop(columns=['translation'], inplace=True)\n","\n","test[['dyu', 'fr']] = test['translation'].apply(pd.Series)\n","test.drop(columns=['translation'], inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-14T10:44:57.189600Z","iopub.status.busy":"2024-08-14T10:44:57.188638Z","iopub.status.idle":"2024-08-14T10:44:57.194426Z","shell.execute_reply":"2024-08-14T10:44:57.193511Z","shell.execute_reply.started":"2024-08-14T10:44:57.189565Z"},"trusted":true},"outputs":[],"source":["print('Length of train data: ', len(train))\n","print('Length of test data: ', len(test))\n","print('Length of validate data: ', len(validate))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-14T10:45:06.720577Z","iopub.status.busy":"2024-08-14T10:45:06.720213Z","iopub.status.idle":"2024-08-14T10:45:06.743574Z","shell.execute_reply":"2024-08-14T10:45:06.742638Z","shell.execute_reply.started":"2024-08-14T10:45:06.720547Z"},"trusted":true},"outputs":[],"source":["train['dyu'] = train['dyu'].apply(lambda x: x.lower())\n","train['fr'] = train['fr'].apply(lambda x: x.lower())\n","\n","validate['dyu'] = validate['dyu'].apply(lambda x: x.lower())\n","validate['fr'] = validate['fr'].apply(lambda x: x.lower())\n","\n","test['dyu'] = test['dyu'].apply(lambda x: x.lower())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-14T10:45:15.318886Z","iopub.status.busy":"2024-08-14T10:45:15.317953Z","iopub.status.idle":"2024-08-14T10:45:15.324725Z","shell.execute_reply":"2024-08-14T10:45:15.323796Z","shell.execute_reply.started":"2024-08-14T10:45:15.318843Z"},"trusted":true},"outputs":[],"source":["train = pd.concat([train, validate], ignore_index=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-14T10:45:23.319527Z","iopub.status.busy":"2024-08-14T10:45:23.319166Z","iopub.status.idle":"2024-08-14T10:45:23.325630Z","shell.execute_reply":"2024-08-14T10:45:23.324648Z","shell.execute_reply.started":"2024-08-14T10:45:23.319499Z"},"trusted":true},"outputs":[],"source":["def dyu_preprocessing(data, col):\n","    data[col] = data[col].astype(str)\n","    data[col] = data[col].apply(lambda x: x.lower())\n","    return data\n","\n","def fr_preprocessing(data, col):\n","    data[col] = data[col].apply(lambda x: x.lower())\n","    #data[col] = \"startseq \"+data[col]+\" endseq\"\n","    return data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-14T10:45:32.163269Z","iopub.status.busy":"2024-08-14T10:45:32.162872Z","iopub.status.idle":"2024-08-14T10:45:32.181442Z","shell.execute_reply":"2024-08-14T10:45:32.180440Z","shell.execute_reply.started":"2024-08-14T10:45:32.163239Z"},"trusted":true},"outputs":[],"source":["train = dyu_preprocessing(train,'dyu')\n","train = fr_preprocessing(train,'fr')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-14T10:45:39.894241Z","iopub.status.busy":"2024-08-14T10:45:39.893860Z","iopub.status.idle":"2024-08-14T10:45:39.922824Z","shell.execute_reply":"2024-08-14T10:45:39.921871Z","shell.execute_reply.started":"2024-08-14T10:45:39.894211Z"},"trusted":true},"outputs":[],"source":["train['dyu_length'] = train['dyu'].apply(lambda x: len(x.split()))\n","train['fr_length'] = train['fr'].apply(lambda x: len(x.split()))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-14T10:45:49.009670Z","iopub.status.busy":"2024-08-14T10:45:49.008720Z","iopub.status.idle":"2024-08-14T10:45:49.024938Z","shell.execute_reply":"2024-08-14T10:45:49.024043Z","shell.execute_reply.started":"2024-08-14T10:45:49.009638Z"},"trusted":true},"outputs":[],"source":["train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-14T10:49:06.544477Z","iopub.status.busy":"2024-08-14T10:49:06.543477Z","iopub.status.idle":"2024-08-14T10:49:06.554762Z","shell.execute_reply":"2024-08-14T10:49:06.553694Z","shell.execute_reply.started":"2024-08-14T10:49:06.544444Z"},"trusted":true},"outputs":[],"source":["df = train.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-14T10:49:21.592130Z","iopub.status.busy":"2024-08-14T10:49:21.591371Z","iopub.status.idle":"2024-08-14T10:49:21.871628Z","shell.execute_reply":"2024-08-14T10:49:21.870613Z","shell.execute_reply.started":"2024-08-14T10:49:21.592094Z"},"trusted":true},"outputs":[],"source":["dyu_tokenizer = Tokenizer()\n","dyu_tokenizer.fit_on_texts(df['dyu'].values)\n","dyu_vocab_size = len(dyu_tokenizer.word_index) + 1\n","dyu_sequences = dyu_tokenizer.texts_to_sequences(df['dyu'].values)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-14T10:49:33.983818Z","iopub.status.busy":"2024-08-14T10:49:33.983124Z","iopub.status.idle":"2024-08-14T10:49:34.275468Z","shell.execute_reply":"2024-08-14T10:49:34.274429Z","shell.execute_reply.started":"2024-08-14T10:49:33.983786Z"},"trusted":true},"outputs":[],"source":["fr_tokenizer = Tokenizer()\n","fr_tokenizer.fit_on_texts(df['fr'].values)\n","fr_vocab_size = len(fr_tokenizer.word_index) + 1\n","fr_sequences = fr_tokenizer.texts_to_sequences(df['fr'].values)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-14T10:49:41.969826Z","iopub.status.busy":"2024-08-14T10:49:41.969454Z","iopub.status.idle":"2024-08-14T10:49:42.053263Z","shell.execute_reply":"2024-08-14T10:49:42.052484Z","shell.execute_reply.started":"2024-08-14T10:49:41.969794Z"},"trusted":true},"outputs":[],"source":["max_dyu_len = df['dyu_length'].max()\n","max_fr_len = df['fr_length'].max()\n","\n","dyu_padded = pad_sequences(dyu_sequences, maxlen=max_dyu_len, padding='post')\n","fr_padded = pad_sequences(fr_sequences, maxlen=max_fr_len, padding='post')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-14T10:49:52.414358Z","iopub.status.busy":"2024-08-14T10:49:52.413957Z","iopub.status.idle":"2024-08-14T10:49:52.421575Z","shell.execute_reply":"2024-08-14T10:49:52.420613Z","shell.execute_reply.started":"2024-08-14T10:49:52.414319Z"},"trusted":true},"outputs":[],"source":["# Display the prepared data\n","print(\"Dyula padded sequences:\")\n","print(dyu_padded[:5])\n","\n","print(\"French padded sequences:\")\n","print(fr_padded[:5])\n","\n","# Save vocabulary sizes for future use\n","print(f\"Dyula Vocabulary Size: {dyu_vocab_size}\")\n","print(f\"French Vocabulary Size: {fr_vocab_size}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-14T10:45:59.261173Z","iopub.status.busy":"2024-08-14T10:45:59.260328Z"},"trusted":true},"outputs":[],"source":["px.histogram(train, x=\"fr_length\",height=700, title=\"French Sentences Length Distribution\", marginal=\"box\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-14T10:46:12.756505Z","iopub.status.busy":"2024-08-14T10:46:12.756134Z"},"trusted":true},"outputs":[],"source":["px.histogram(train, x=\"dyu_length\",height=700, title=\"Dyulu Sentences Length Distribution\", marginal=\"box\")"]},{"cell_type":"markdown","metadata":{},"source":["## Multi Head Attention Model Implementation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-14T10:52:41.536966Z","iopub.status.busy":"2024-08-14T10:52:41.536239Z","iopub.status.idle":"2024-08-14T10:53:14.853766Z","shell.execute_reply":"2024-08-14T10:53:14.852792Z","shell.execute_reply.started":"2024-08-14T10:52:41.536938Z"},"trusted":true},"outputs":[],"source":["# Load GloVe Embeddings\n","def load_glove_embeddings(glove_file, embedding_dim=300):\n","    embeddings_index = {}\n","    with open(glove_file, 'r', encoding='utf-8') as f:\n","        for line in f:\n","            values = line.split()\n","            word = values[0]\n","            embedding_vector = np.asarray(values[1:], dtype='float32')\n","            embeddings_index[word] = embedding_vector\n","    return embeddings_index\n","\n","# Create Embedding Matrix\n","def create_embedding_matrix(tokenizer, embeddings_index, embedding_dim=300):\n","    vocab_size = len(tokenizer.word_index) + 1\n","    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n","    for word, i in tokenizer.word_index.items():\n","        embedding_vector = embeddings_index.get(word)\n","        if embedding_vector is not None:\n","            embedding_matrix[i] = embedding_vector\n","    return embedding_matrix\n","\n","# Load GloVe embeddings\n","glove_file = '/kaggle/input/glove-text-embeddings/glove.6B.300d.txt'\n","embedding_dim = 300\n","embeddings_index = load_glove_embeddings(glove_file, embedding_dim)\n","\n","# Create embedding matrices for Dyula and French\n","dyu_embedding_matrix = create_embedding_matrix(dyu_tokenizer, embeddings_index, embedding_dim)\n","fr_embedding_matrix = create_embedding_matrix(fr_tokenizer, embeddings_index, embedding_dim)\n","\n","# Display embedding matrix shapes\n","print(f\"Dyula Embedding Matrix Shape: {dyu_embedding_matrix.shape}\")\n","print(f\"French Embedding Matrix Shape: {fr_embedding_matrix.shape}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-14T10:47:28.961698Z","iopub.status.busy":"2024-08-14T10:47:28.960879Z","iopub.status.idle":"2024-08-14T10:47:28.968265Z","shell.execute_reply":"2024-08-14T10:47:28.967278Z","shell.execute_reply.started":"2024-08-14T10:47:28.961666Z"},"trusted":true},"outputs":[],"source":["def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n","    # Multi-Head Self Attention\n","    x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(inputs, inputs)\n","    x = Dropout(dropout)(x)\n","    x = Add()([x, inputs])\n","    x = LayerNormalization(epsilon=1e-6)(x)\n","    \n","    # Feed Forward Network\n","    x_ffn = Dense(ff_dim, activation=\"relu\")(x)\n","    x_ffn = Dropout(dropout)(x_ffn)\n","    x_ffn = Dense(inputs.shape[-1])(x_ffn)\n","    x_ffn = Add()([x_ffn, x])\n","    x_ffn = LayerNormalization(epsilon=1e-6)(x_ffn)\n","    return x_ffn"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-14T10:47:37.941583Z","iopub.status.busy":"2024-08-14T10:47:37.940900Z","iopub.status.idle":"2024-08-14T10:47:37.946188Z","shell.execute_reply":"2024-08-14T10:47:37.945206Z","shell.execute_reply.started":"2024-08-14T10:47:37.941553Z"},"trusted":true},"outputs":[],"source":["head_size = 256  # Size of each attention head\n","num_heads = 40 # Number of attention heads\n","ff_dim = 512  # Hidden layer size in feed-forward network\n","dropout = 0.1  # Dropout rate\n","embedding_dim = 300  # Dimension of word embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-14T10:54:09.453351Z","iopub.status.busy":"2024-08-14T10:54:09.452974Z","iopub.status.idle":"2024-08-14T10:54:09.538708Z","shell.execute_reply":"2024-08-14T10:54:09.537686Z","shell.execute_reply.started":"2024-08-14T10:54:09.453316Z"},"trusted":true},"outputs":[],"source":["# Encoder\n","encoder_inputs = Input(shape=(None,), name='encoder_inputs')\n","encoder_embedding = Embedding(input_dim=dyu_vocab_size, \n","                              output_dim=embedding_dim, \n","                              weights=[dyu_embedding_matrix], \n","                              input_length=max_dyu_len, \n","                              trainable=False, \n","                              name='encoder_embedding')(encoder_inputs)\n","\n","# Pass through multiple transformer encoder layers\n","encoder_outputs = transformer_encoder(encoder_embedding, head_size, num_heads, ff_dim, dropout)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-14T10:54:06.065779Z","iopub.status.busy":"2024-08-14T10:54:06.065414Z","iopub.status.idle":"2024-08-14T10:54:06.173588Z","shell.execute_reply":"2024-08-14T10:54:06.172816Z","shell.execute_reply.started":"2024-08-14T10:54:06.065749Z"},"trusted":true},"outputs":[],"source":["# Decoder\n","decoder_inputs = Input(shape=(None,), name='decoder_inputs')\n","decoder_embedding = Embedding(input_dim=fr_vocab_size, \n","                              output_dim=embedding_dim, \n","                              weights=[fr_embedding_matrix], \n","                              input_length=max_fr_len, \n","                              trainable=False, \n","                              name='decoder_embedding')(decoder_inputs)\n","\n","# Pass through multiple transformer encoder layers (used in decoder as well)\n","decoder_outputs = transformer_encoder(decoder_embedding, head_size, num_heads, ff_dim, dropout)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-14T10:54:19.565932Z","iopub.status.busy":"2024-08-14T10:54:19.565286Z","iopub.status.idle":"2024-08-14T10:54:19.622299Z","shell.execute_reply":"2024-08-14T10:54:19.621422Z","shell.execute_reply.started":"2024-08-14T10:54:19.565901Z"},"trusted":true},"outputs":[],"source":["# Output layer\n","output_layer = Dense(fr_vocab_size, activation='softmax', name='output_layer')(decoder_outputs)\n","\n","# Define the model\n","model = Model([encoder_inputs, decoder_inputs], output_layer)\n","\n","# Compile the model\n","model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# Model summary\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-14T10:54:32.163222Z","iopub.status.busy":"2024-08-14T10:54:32.162633Z","iopub.status.idle":"2024-08-14T10:54:32.167559Z","shell.execute_reply":"2024-08-14T10:54:32.166659Z","shell.execute_reply.started":"2024-08-14T10:54:32.163192Z"},"trusted":true},"outputs":[],"source":["# Prepare target sequences\n","decoder_input_data = fr_padded[:, :-1]\n","decoder_target_data = np.expand_dims(fr_padded[:, 1:], -1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-14T10:54:39.547394Z","iopub.status.busy":"2024-08-14T10:54:39.546594Z","iopub.status.idle":"2024-08-14T10:54:39.555757Z","shell.execute_reply":"2024-08-14T10:54:39.554858Z","shell.execute_reply.started":"2024-08-14T10:54:39.547361Z"},"trusted":true},"outputs":[],"source":["# Split the data\n","encoder_input_train, encoder_input_val, decoder_input_train, decoder_input_val, decoder_target_train, decoder_target_val = train_test_split(\n","    dyu_padded, decoder_input_data, decoder_target_data, test_size=0.2\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-14T10:55:02.382966Z","iopub.status.busy":"2024-08-14T10:55:02.382605Z","iopub.status.idle":"2024-08-14T11:02:08.826185Z","shell.execute_reply":"2024-08-14T11:02:08.825344Z","shell.execute_reply.started":"2024-08-14T10:55:02.382936Z"},"trusted":true},"outputs":[],"source":["# Train the model\n","batch_size = 30\n","epochs = 100\n","history = model.fit(\n","    [encoder_input_train, decoder_input_train],\n","    decoder_target_train,\n","    batch_size=batch_size,\n","    epochs=epochs,\n","    validation_data=([encoder_input_val, decoder_input_val], decoder_target_val)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-14T11:14:19.592963Z","iopub.status.busy":"2024-08-14T11:14:19.592606Z","iopub.status.idle":"2024-08-14T11:14:20.291708Z","shell.execute_reply":"2024-08-14T11:14:20.290758Z","shell.execute_reply.started":"2024-08-14T11:14:19.592933Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import random\n","from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","\n","def sequence_to_text(sequence, tokenizer):\n","    return ' '.join([tokenizer.index_word.get(i, '') for i in sequence if i > 0])\n","\n","# Generate predictions for a subset of test sentences\n","num_samples = 10  # Change this to any number of samples you want\n","random_indices = random.sample(range(len(encoder_input_val)), num_samples)\n","\n","# Collect predictions, actual sentences, and BLEU scores\n","predicted_sentences = []\n","actual_sentences = []\n","bleu_scores = []\n","\n","for idx in random_indices:\n","    # Prepare inputs\n","    encoder_input_seq = np.expand_dims(encoder_input_val[idx], axis=0)\n","    decoder_input_seq = np.expand_dims(decoder_input_val[idx], axis=0)\n","    \n","    # Predict the output sequence\n","    pred_seq = model.predict([encoder_input_seq, decoder_input_seq])\n","    pred_seq = np.argmax(pred_seq, axis=-1).flatten()\n","    \n","    # Convert sequences to text\n","    predicted_sentence = sequence_to_text(pred_seq, fr_tokenizer)\n","    actual_sentence = sequence_to_text(decoder_target_val[idx].flatten(), fr_tokenizer)\n","    \n","    # Check if the predicted sentence is not empty\n","    if predicted_sentence.strip():\n","        # Calculate BLEU score\n","        ref_tokens = [actual_sentence.split()]\n","        pred_tokens = predicted_sentence.split()\n","        smoothie = SmoothingFunction().method4\n","        bleu_score = sentence_bleu(ref_tokens, pred_tokens, smoothing_function=smoothie)\n","    else:\n","        bleu_score = 0.0  # Assign a BLEU score of 0 if the predicted sentence is empty\n","    \n","    # Append results\n","    predicted_sentences.append(predicted_sentence)\n","    actual_sentences.append(actual_sentence)\n","    bleu_scores.append(bleu_score)\n","    \n","# Print results\n","for i in range(num_samples):\n","    print(f\"Original Dyula Sentence (ID: {random_indices[i]}):\")\n","    print(sequence_to_text(encoder_input_val[random_indices[i]], dyu_tokenizer))\n","    print(f\"Predicted French Sentence: {predicted_sentences[i]}\")\n","    print(f\"Actual French Sentence: {actual_sentences[i]}\")\n","    print(f\"BLEU Score: {bleu_scores[i]:.4f}\\n\")\n","\n","# Calculate average BLEU score\n","average_bleu = np.mean(bleu_scores)\n","print(f\"Average BLEU Score for Sampled Sentences: {average_bleu:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5532212,"sourceId":9157404,"sourceType":"datasetVersion"},{"datasetId":5542733,"sourceId":9171996,"sourceType":"datasetVersion"}],"dockerImageVersionId":30747,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":4}
